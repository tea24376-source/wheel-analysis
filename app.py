import streamlit as st
import cv2
import numpy as np
import pandas as pd
from scipy.signal import savgol_filter
import tempfile
import os
import matplotlib.pyplot as plt
import io

# Matplotlibè¨­å®š
plt.switch_backend('Agg')
plt.rcParams['mathtext.fontset'] = 'cm'

# --- ã‚°ãƒ©ãƒ•æç”»é–¢æ•° (ã‚¬ãƒ¼ãƒ‰ä»˜ã) ---
def create_graph_image(df_sub, x_col, y_col, x_label_text, y_label_text, x_unit, y_unit, color, size, x_min, x_max, y_min, y_max):
    fig, ax = plt.subplots(figsize=(size/100, size/100), dpi=100)
    
    if len(df_sub) > 0:
        ax.plot(df_sub[x_col], df_sub[y_col], color=color, linewidth=2)
        ax.scatter(df_sub[x_col].iloc[-1], df_sub[y_col].iloc[-1], color=color, s=50)
    
    ax.set_title(f"${y_label_text}$ - ${x_label_text}$", fontsize=16, fontweight='bold')
    ax.set_xlabel(f"${x_label_text}$ [{x_unit}]", fontsize=14)
    ax.set_ylabel(f"${y_label_text}$ [{y_unit}]", fontsize=14)
    
    # è»¸ç¯„å›²ã®ã‚¨ãƒ©ãƒ¼é˜²æ­¢
    x_range = max(float(x_max - x_min), 0.001)
    ax.set_xlim(x_min - x_range*0.05, x_max + x_range*0.05)
    
    y_range = max(float(y_max - y_min), 0.001)
    ax.set_ylim(y_min - y_range*0.1, y_max + y_range*0.1)
    
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.axhline(0, color='black', linewidth=1, alpha=0.5)
    if x_col != 't':
        ax.axvline(0, color='black', linewidth=1, alpha=0.5)
        
    plt.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png", facecolor='white')
    buf.seek(0)
    img = cv2.imdecode(np.frombuffer(buf.getvalue(), dtype=np.uint8), 1)
    plt.close(fig)
    return cv2.resize(img, (size, size))

st.set_page_config(page_title="CartGrapher Studio", layout="wide")
st.title("ğŸš€ CartGrapher Studio")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šKinema-Cartè¨­å®š ---
st.sidebar.header("Kinema-Cart è¨­å®š")
radius_cm = st.sidebar.slider("è»Šè¼ªã®åŠå¾„ (cm)", 0.5, 5.0, 1.6, 0.1)
mass = st.sidebar.number_input("å°è»Šã®è³ªé‡ $m$ (kg)", value=0.1, min_value=0.001, step=0.01, format="%.3f")
mask_size = st.sidebar.slider("è§£æã‚¨ãƒªã‚¢åŠå¾„ (px)", 50, 400, 200, 10)

LOWER_GREEN = (np.array([35, 50, 50]), np.array([85, 255, 255]))
LOWER_PINK = (np.array([140, 40, 40]), np.array([180, 255, 255]))

uploaded_file = st.file_uploader("å®Ÿé¨“å‹•ç”»ã‚’é¸æŠ (MP4/MOV)", type=["mp4", "mov"])

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(uploaded_file.read())
    
    cap = cv2.VideoCapture(tfile.name)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    w_orig = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h_orig = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    status = st.empty()
    progress_bar = st.progress(0.0)
    
    # --- Step 1: è§£æ ---
    data_log = []
    total_angle = 0.0
    prev_angle = None
    gx, gy = np.nan, np.nan
    frame_count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        
        # ç·‘ï¼ˆä¸­å¿ƒï¼‰
        mask_g = cv2.inRange(hsv, LOWER_GREEN[0], LOWER_GREEN[1])
        con_g, _ = cv2.findContours(mask_g, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if con_g:
            c = max(con_g, key=cv2.contourArea)
            M = cv2.moments(c)
            if M["m00"] != 0:
                gx, gy = M["m10"]/M["m00"], M["m01"]/M["m00"]

        # ãƒ”ãƒ³ã‚¯ï¼ˆå¤–å‘¨ï¼‰
        bx, by = np.nan, np.nan
        if pd.notna(gx):
            circle_mask = np.zeros((h_orig, w_orig), dtype=np.uint8)
            cv2.circle(circle_mask, (int(gx), int(gy)), mask_size, 255, -1)
            mask_p = cv2.inRange(cv2.bitwise_and(hsv, hsv, mask=circle_mask), LOWER_PINK[0], LOWER_PINK[1])
            con_p, _ = cv2.findContours(mask_p, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if con_p:
                cp = max(con_p, key=cv2.contourArea)
                Mp = cv2.moments(cp)
                if Mp["m00"] != 0: bx, by = Mp["m10"]/Mp["m00"], Mp["m01"]/Mp["m00"]

        if pd.notna(gx) and pd.notna(bx):
            current_angle = np.arctan2(by - gy, bx - gx)
            if prev_angle is not None:
                diff = current_angle - prev_angle
                if diff > np.pi: diff -= 2 * np.pi
                if diff < -np.pi: diff += 2 * np.pi
                total_angle += diff 
            prev_angle = current_angle

        data_log.append({"t": frame_count/fps, "x": total_angle * (radius_cm/100), "gx": gx, "gy": gy, "bx": bx, "by": by})
        frame_count += 1
        if frame_count % 10 == 0: progress_bar.progress(min(frame_count / total_frames * 0.3, 0.3))
    cap.release()

    # --- Step 2: ç‰©ç†é‡è¨ˆç®— ---
    df = pd.DataFrame(data_log).interpolate().ffill().bfill().fillna(0)
    df["x"] = savgol_filter(df["x"], 15, 2)
    df["v"] = savgol_filter(df["x"].diff().fillna(0) * fps, 31, 2)
    df["a"] = savgol_filter(df["v"].diff().fillna(0) * fps, 31, 2)
    df["F"] = mass * df["a"]
    # å†åº¦NaNåŸ‹ã‚
    df = df.fillna(0)

    # å…¨åŸŸã®ã‚¹ã‚±ãƒ¼ãƒ«å–å¾—
    t_min, t_max = 0, float(df["t"].max())
    x_min, x_max = float(df["x"].min()), float(df["x"].max())
    v_min, v_max = float(df["v"].min()), float(df["v"].max())
    a_min, a_max = float(df["a"].min()), float(df["a"].max())
    F_min, F_max = float(df["F"].min()), float(df["F"].max())

    # --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º ---
    st.subheader("ğŸ“Š ç‰©ç†ã‚°ãƒ©ãƒ•ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    p_size = 500
    row1_c1, row1_c2 = st.columns(2)
    with row1_c1: st.image(create_graph_image(df, "t", "x", "t", "x", "s", "m", "blue", p_size, t_min, t_max, x_min, x_max), channels="BGR")
    with row1_c2: st.image(create_graph_image(df, "t", "v", "t", "v", "s", "m/s", "red", p_size, t_min, t_max, v_min, v_max), channels="BGR")
    row2_c1, row2_c2 = st.columns(2)
    with row2_c1: st.image(create_graph_image(df, "t", "a", "t", "a", "s", "m/s^2", "green", p_size, t_min, t_max, a_min, a_max), channels="BGR")
    with row2_c2: st.image(create_graph_image(df, "x", "F", "x", "F", "m", "N", "purple", p_size, x_min, x_max, F_min, F_max), channels="BGR")

    # --- â˜… ä»•äº‹ W ã®è¨ˆç®—ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    st.divider()
    st.subheader("ğŸ”¬ ã‚¨ãƒãƒ«ã‚®ãƒ¼è§£æï¼šä»•äº‹ $W$")
    st.write("$F-x$ ã‚°ãƒ©ãƒ•ã®é¢ç©ã‹ã‚‰ã€æŒ‡å®šåŒºé–“ã®ä»•äº‹ $W$ ã‚’ç®—å‡ºã—ã¾ã™ã€‚")
    
    calc_c1, calc_c2, calc_c3 = st.columns([2, 2, 3])
    with calc_c1: t_s = st.number_input("é–‹å§‹æ™‚åˆ» $t$ [s]", 0.0, t_max, 0.0, 0.1)
    with calc_c2: t_e = st.number_input("çµ‚äº†æ™‚åˆ» $t$ [s]", 0.0, t_max, t_max, 0.1)
    
    df_w = df[(df['t'] >= t_s) & (df['t'] <= t_e)]
    if len(df_w) > 1:
        # ç©åˆ†è¨ˆç®—
        w_val = np.trapz(df_w['F'], df_w['x'])
        with calc_c3:
            st.metric(label="ä»•äº‹ $W$ [J]", value=f"{w_val:.4f} J")
            st.info(f"åŒºé–“å¤‰ä½: $\Delta x = {df_w['x'].iloc[-1] - df_w['x'].iloc[0]:.3f}$ m")
    else:
        st.warning("æœ‰åŠ¹ãªç¯„å›²ã‚’é¸æŠã—ã¦ãã ã•ã„")

    # --- Step 3: å‹•ç”»åˆæˆ ---
    status.info("å‹•ç”»ç”Ÿæˆä¸­...")
    g_v_size = w_orig // 4
    header_h = g_v_size + 100 
    final_v_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
    out = cv2.VideoWriter(final_v_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w_orig, h_orig + header_h))
    
    cap_re = cv2.VideoCapture(tfile.name)
    font_it = cv2.FONT_HERSHEY_SIMPLEX | cv2.FONT_ITALIC

    for i in range(len(df)):
        ret, frame = cap_re.read()
        if not ret: break
        canvas = np.zeros((h_orig + header_h, w_orig, 3), dtype=np.uint8)
        curr = df.iloc[i]
        
        # 4ã¤ã®ã‚°ãƒ©ãƒ•
        gs = [
            create_graph_image(df.iloc[:i+1], "t", "x", "t", "x", "s", "m", "blue", g_v_size, t_min, t_max, x_min, x_max),
            create_graph_image(df.iloc[:i+1], "t", "v", "t", "v", "s", "m/s", "red", g_v_size, t_min, t_max, v_min, v_max),
            create_graph_image(df.iloc[:i+1], "t", "a", "t", "a", "s", "m/s^2", "green", g_v_size, t_min, t_max, a_min, a_max),
            create_graph_image(df.iloc[:i+1], "x", "F", "x", "F", "m", "N", "purple", g_v_size, x_min, x_max, F_min, F_max)
        ]
        for idx, g_img in enumerate(gs):
            canvas[0:g_v_size, idx*g_v_size:(idx+1)*g_v_size] = g_img

        # æ•°å€¤è¡¨ç¤º
        labels = [f"x: {curr['x']:.3f} m", f"v: {curr['v']:.2f} m/s", f"a: {curr['a']:.2f} m/s2", f"F: {curr['F']:.3f} N"]
        for idx, txt in enumerate(labels):
            ts = cv2.getTextSize(txt, font_it, 0.9, 2)[0]
            cv2.putText(canvas, txt, (idx*g_v_size + (g_v_size-ts[0])//2, g_v_size+60), font_it, 0.9, (255,255,255), 2)

        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æç”»
        if pd.notna(curr['gx']):
            cv2.circle(frame, (int(curr['gx']), int(curr['gy'])), mask_size, (200, 200, 200), 2)
            cv2.circle(frame, (int(curr['gx']), int(curr['gy'])), 6, (0, 255, 0), -1)
            if pd.notna(curr['bx']):
                cv2.circle(frame, (int(curr['bx']), int(curr['by'])), 6, (255, 0, 255), -1)
                cv2.line(frame, (int(curr['gx']), int(curr['gy'])), (int(curr['bx']), int(curr['by'])), (255, 255, 255), 1)

        canvas[header_h:, 0:w_orig] = frame
        t_txt = f"t: {curr['t']:.2f} s"
        t_sz = cv2.getTextSize(t_txt, font_it, 1.1, 2)[0]
        cv2.putText(canvas, t_txt, (w_orig - t_sz[0] - 20, h_orig + header_h - 30), font_it, 1.1, (255, 255, 255), 2)
        out.write(canvas)
    
    cap_re.release()
    out.release()
    status.success("ã™ã¹ã¦ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    st.divider()
    st.download_button("ğŸ“Š CSVãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", df[["t", "x", "v", "a", "F"]].to_csv(index=False).encode('utf_8_sig'), "kinema_cart_data.csv", "text/csv")
    with open(final_v_path, "rb") as f:
        st.download_button("ğŸ¥ è§£æå‹•ç”»ã‚’ä¿å­˜", f, "cart_grapher_output.mp4", "video/mp4")
    os.remove(tfile.name)
